{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feature_extraction_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jontooy/vl_demos/blob/master/feature_extraction_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxWUgr_Ta50Q"
      },
      "source": [
        "# VinVL_feature_extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUQdkFxafciq",
        "outputId": "e0539d5a-8cb0-49f2-b693-29c44bcfa714"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import os.path as op\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import ast\n",
        "import json\n",
        "import base64\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ik1FAZCTI1I"
      },
      "source": [
        "## Install **sgg**:\n",
        "https://github.com/microsoft/scene_graph_benchmark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone repos\n",
        "% cd /content/drive/MyDrive\n",
        "\n",
        "! git clone https://github.com/microsoft/scene_graph_benchmark.git\n",
        "\n",
        "# get model file to your mount disk\n",
        "! wget https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/vinvl_vg_x152c4.pth -P /content/drive/MyDrive/scene_graph_benchmark/pretrained_model\n",
        "\n",
        "# get object detection mapping\n",
        "! wget https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/VG-SGG-dicts-vgoi6-clipped.json -P /content/drive/MyDrive/scene_graph_benchmark/visualgenome/\n",
        "\n",
        "% cd /content/drive/MyDrive/scene_graph_benchmark/\n",
        "\n",
        "# maskrcnn_benchmark and coco api dependencies\n",
        "! pip install ninja yacs>=0.1.8 cython matplotlib tqdm opencv-python numpy>=1.19.5\n",
        "\n",
        "! pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip install timm\n",
        "! pip install einops\n",
        "! pip install -U PyYAML\n",
        "\n",
        "# install pycocotools\n",
        "! pip install pycocotools\n",
        "\n",
        "# install cityscapesScripts\n",
        "! python -m pip install cityscapesscripts\n",
        "\n",
        "# the following will install the lib with\n",
        "# symbolic links, so that you can modify\n",
        "# the files if you want and won't need to\n",
        "# re-build it\n",
        "! python setup.py build develop"
      ],
      "metadata": {
        "id": "7zs23zoeKxCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiQ6Q0W3zzT9"
      },
      "source": [
        "## Image extraction pipeline\n",
        "\n",
        "1. Drop images to process into /content/drive/MyDrive/scene_graph_benchmark/tools/mini_tsv/images OR change data_path in tools\\tsv_demo.py to image folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3juHnNH3RIcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35dd37a-e925-4c33-e637-4bf08abacd8c"
      },
      "source": [
        "TSV_DIR = './tools/mini_tsv/data'\n",
        "# Create .tsv files for our images\n",
        "! python /content/drive/MyDrive/scene_graph_benchmark/tools/mini_tsv/tsv_demo.py\n",
        "\n",
        "# Create .yaml file for connecting .tsv files\n",
        "yaml_dict = {\"img\" : \"train.tsv\",\n",
        "            \"label\" :  \"train.label.tsv\",\n",
        "            \"hw\" : \"train.hw.tsv\",\n",
        "            \"linelist\" : \"train.linelist.tsv\"}\n",
        "with open(op.join(TSV_DIR, 'train.yaml'), 'w') as file:\n",
        "        yaml.dump(yaml_dict, file)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\r3it [00:00, 3744.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ-FWBEud4fP"
      },
      "source": [
        "2. Configure sgg_configs/vgattr/vinvl_x152c4.yaml and make sure os.path.join(DATA_DIR, DATASETS.TEST) is to your dataset yaml file. Current settings:\n",
        "\n",
        "  + DATASETS.TEST: (\"train.yaml\",)\n",
        "  + OUTPUT_DIR: \"output/\"\n",
        "  + DATA_DIR: \"tools/mini_tsv/data/\"\n",
        "\n",
        "If you have problems loading the label map, edit line 37 in maskrcnn_benchmark/data/datasets/relation_tsv.py to an absolute path:\n",
        "\n",
        "```\n",
        "open('/content/drive/MyDrive/scene_graph_benchmark/visualgenome/VG-SGG-dicts-vgoi6-clipped.json', 'r')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1GNtdBHR3Bv"
      },
      "source": [
        "# extract vision features with VinVL object-attribute detection model\n",
        "# pretrained models at https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/vinvl_vg_x152c4.pth\n",
        "# the associated labelmap at https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/VG-SGG-dicts-vgoi6-clipped.json\n",
        "! python tools/test_sg_net.py \\\n",
        "  --config-file sgg_configs/vgattr/vinvl_x152c4.yaml \\\n",
        "  TEST.IMS_PER_BATCH 2 \\\n",
        "  MODEL.WEIGHT pretrained_model/vinvl_vg_x152c4.pth \\\n",
        "  MODEL.ROI_HEADS.NMS_FILTER 1 \\\n",
        "  MODEL.ROI_HEADS.SCORE_THRESH 0.2 \\\n",
        "  TEST.OUTPUT_FEATURE True \\\n",
        "  OUTPUT_DIR output \\\n",
        "  DATA_DIR tools/mini_tsv/data \\\n",
        "  TEST.IGNORE_BOX_REGRESSION True \\\n",
        "  MODEL.ATTRIBUTE_ON True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load height and width of every image\n",
        "hw_df = pd.read_csv(op.join(TSV_DIR, 'train.hw.tsv'),sep='\\t',header=None,converters={1:ast.literal_eval},index_col=0)\n",
        "\n",
        "# Directory of out predictions.tsv (bbox_id, class, conf, feature, rect)\n",
        "sg_tsv = './output/inference/vinvl_vg_x152c4/predictions.tsv'\n",
        "df = pd.read_csv(sg_tsv,sep='\\t',header = None,converters={1:json.loads})#converters={1:ast.literal_eval})\n",
        "df[1] = df[1].apply(lambda x: x['objects'])\n",
        "\n",
        "# Help functions\n",
        "def generate_additional_features(rect,h,w):\n",
        "    mask = np.array([w,h,w,h],dtype=np.float32)\n",
        "    rect = np.clip(rect/mask,0,1)\n",
        "    res = np.hstack((rect,[rect[3]-rect[1], rect[2]-rect[0]]))\n",
        "    return res.astype(np.float32)\n",
        "\n",
        "def generate_features(x):\n",
        "    #image_id, object data list of dictionary, number of detected objects\n",
        "    idx, data,num_boxes = x[0],x[1],len(x[1])\n",
        "    # read image height, width, and initialize array of features\n",
        "    h,w,features_arr = hw_df.loc[idx,1][0]['height'],hw_df.loc[idx,1][0]['width'],[]\n",
        "\n",
        "    # for every detected object in img\n",
        "    for i in range(num_boxes):\n",
        "        # read image region feature vector\n",
        "        features = np.frombuffer(base64.b64decode(data[i]['feature']),np.float32)\n",
        "        # add 6 additional dimensions\n",
        "        pos_feat = generate_additional_features(data[i]['rect'],h,w)\n",
        "        # stack feature vector with 6 additional dimensions\n",
        "        x = np.hstack((features,pos_feat))\n",
        "        features_arr.append(x.astype(np.float32))\n",
        "        \n",
        "    features = np.vstack(tuple(features_arr))\n",
        "    print(features.shape)\n",
        "    features = base64.b64encode(features).decode(\"utf-8\")\n",
        "    return {\"features\":features, \"num_boxes\":num_boxes}\n",
        "\n",
        "def generate_labels(x):\n",
        "    data = x[1]\n",
        "    res = [{\"class\":el['class'].capitalize(),\"conf\":el['conf'], \"rect\": el['rect']} for el in data] \n",
        "    return res\n",
        "\n",
        "# Generate features from predictions.tsv\n",
        "df['feature'] = df.apply(generate_features,axis=1)\n",
        "df['feature'] = df['feature'].apply(json.dumps)\n",
        "\n",
        "df['label'] = df.apply(generate_labels,axis=1)\n",
        "df['label'] = df['label'].apply(json.dumps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyWLa8PoQIOW",
        "outputId": "876804e0-3b17-4db4-e419-6b8c20defa64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63, 2054)\n",
            "(44, 2054)\n",
            "(29, 2054)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1rCtd7qeGCF"
      },
      "source": [
        "3. Make sure you change the OUTPUT_DIR and TYPE variable in the script below to your dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGC2ryeLRp0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f57ce28-90da-4aa9-d137-76f9cb4062a0"
      },
      "source": [
        "# Load height and width of every image\n",
        "hw_df = pd.read_csv(op.join(TSV_DIR, 'train.hw.tsv'),sep='\\t',header=None,converters={1:ast.literal_eval},index_col=0)\n",
        "\n",
        "# Directory of out predictions.tsv (bbox_id, class, conf, feature, rect)\n",
        "sg_tsv = './output/inference/vinvl_vg_x152c4/predictions.tsv'\n",
        "df = pd.read_csv(sg_tsv,sep='\\t',header = None,converters={1:json.loads})#converters={1:ast.literal_eval})\n",
        "df[1] = df[1].apply(lambda x: x['objects'])\n",
        "\n",
        "# Help functions\n",
        "def generate_additional_features(rect,h,w):\n",
        "    mask = np.array([w,h,w,h],dtype=np.float32)\n",
        "    rect = np.clip(rect/mask,0,1)\n",
        "    res = np.hstack((rect,[rect[3]-rect[1], rect[2]-rect[0]]))\n",
        "    return res.astype(np.float32)\n",
        "\n",
        "def generate_features(x):\n",
        "    #image_id, object data list of dictionary, number of detected objects\n",
        "    idx, data,num_boxes = x[0],x[1],len(x[1])\n",
        "    # read image height, width, and initialize array of features\n",
        "    h,w,features_arr = hw_df.loc[idx,1][0]['height'],hw_df.loc[idx,1][0]['width'],[]\n",
        "\n",
        "    # for every detected object in img\n",
        "    for i in range(num_boxes):\n",
        "        # read image region feature vector\n",
        "        features = np.frombuffer(base64.b64decode(data[i]['feature']),np.float32)\n",
        "        # add 6 additional dimensions\n",
        "        pos_feat = generate_additional_features(data[i]['rect'],h,w)\n",
        "        # stack feature vector with 6 additional dimensions\n",
        "        x = np.hstack((features,pos_feat))\n",
        "        features_arr.append(x.astype(np.float32))\n",
        "        \n",
        "    features = np.vstack(tuple(features_arr))\n",
        "    features = base64.b64encode(features).decode(\"utf-8\")\n",
        "    return {\"features\":features, \"num_boxes\":num_boxes}\n",
        "\n",
        "def generate_labels(x):\n",
        "    data = x[1]\n",
        "    res = [{\"class\":el['class'].capitalize(),\"conf\":el['conf'], \"rect\": el['rect']} for el in data] \n",
        "    return res\n",
        "\n",
        "# Generate features from predictions.tsv\n",
        "df['feature'] = df.apply(generate_features,axis=1)\n",
        "df['feature'] = df['feature'].apply(json.dumps)\n",
        "\n",
        "df['label'] = df.apply(generate_labels,axis=1)\n",
        "df['label'] = df['label'].apply(json.dumps)\n",
        "\n",
        "# Generate train/test/val.label.tsv and train/test/val.feature.tsv\n",
        "TYPE = 'train'\n",
        "include_caption = True\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/dataset'\n",
        "LABEL_FILE = os.path.join(OUTPUT_DIR, TYPE+'.label.tsv')\n",
        "FEATURE_FILE = os.path.join(OUTPUT_DIR, TYPE+'.feature.tsv')\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\"path to {OUTPUT_DIR} created\")\n",
        "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
        "tsv_writer(df[[0,'label']].values.tolist(),LABEL_FILE)\n",
        "tsv_writer(df[[0,'feature']].values.tolist(),FEATURE_FILE)\n",
        "\n",
        "# Generate TYPE.yaml for vinvl run_captioning\n",
        "yaml_dict = {\"img\" : TYPE+\".img.tsv\",\n",
        "             \"hw\" : TYPE+\".hw.tsv\",\n",
        "             \"label\": TYPE+\".label.tsv\",\n",
        "             \"feature\": TYPE+\".feature.tsv\"}\n",
        "if include_caption:\n",
        "  yaml_dict[\"caption\"] = TYPE+\"_caption.json\" \n",
        "with open(op.join(OUTPUT_DIR, TYPE+'.yaml'), 'w') as file:\n",
        "        yaml.dump(yaml_dict, file)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path to /content/drive/MyDrive/dataset created\n"
          ]
        }
      ]
    }
  ]
}